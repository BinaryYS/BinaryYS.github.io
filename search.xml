<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深入理解JVM]]></title>
    <url>%2F2017%2F06%2F16%2F%E7%AC%94%E8%AE%B0%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%2F</url>
    <content type="text"><![CDATA[前言 java是世界上最好的语言！！！]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-github搭建博客]]></title>
    <url>%2F2017%2F06%2F16%2F%E6%95%99%E7%A8%8B%2Fhexo-github%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[1.安装git1.1 安装好git之后一定要配置好环境变量 （PATH中添加X:\Git\bin;X:\Git\libexec\git-core）否则提交代码到远程会报 git error 2.安装node.js2.1 配置环境变量 (貌似安装node.js时自动配置了，如果没有自行添加)2.2 在dos窗口执行node -v检查配置是否完成 3.配置github3.1 如果没有github账号，则参考教程申请账号、配置连接 有道云教程3.2 创建远程仓库blog用于管理博客源码,本地拉取blog的源码3.3 创建远程仓库用于存放编译blog生成的public文件，也就是能够访问到的静态文件，命名格式为 github账号.github.io 4.创建本地博客(执行命令用git bash)4.1 安装hexo,执行命令1npm install -g hexo-cli 4.2 新建一个localblog文件，执行命令生成hexo文件1$ hexo init 4.3 将localblog中生成的文件全部拷贝到远程拉取的blog项目中 4.4 在blog目录下执行命令拉取依赖的包1$ npm install 4.5 执行命令安装hexo-deployer-git1$ npm install hexo-deployer-git --save 4.6 清除缓存1$ hexo clean 4.7 编译1$ hexo g 4.9 本地指定端口启动，localhost:5000访问1$ hexo s -p 5000 5.部署到远程仓库github账号.github.io5.1 修改配置文件_config.yml1234deploy: type: git repo: github: git@github.com:github账号/github账号.github.io.git 5.2 执行命令清除缓存 hexo clean1$ hexo clean 5.3 编译1$ hexo g 5.4 推送至远程仓库github账号.github.io1$ hexo d 5.5 访问blog,https://github账号.github.io]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库查询优化]]></title>
    <url>%2F2017%2F02%2F23%2F%E7%AC%94%E8%AE%B0%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[数据库设计方面A:对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。B:应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：12select id from t where num is null select id from t where num=0 C: 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时,查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用D:索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要E:应尽可能的避免更新索引数据列，因为索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新索引数据列，那么需要考虑是否应将该索引建为索引F:尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了G:尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些H:尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）I:在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。12create table TEMP_CCS_ACCT_20170103 as SELECT * from CCS_ACCT a where a.CONTR_NBR in ('');insert into table_A select * from table_B SQL方面]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>查询</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL分片]]></title>
    <url>%2F2017%2F02%2F14%2F%E7%AC%94%E8%AE%B0%2FMySQL%2FMySQL%E5%88%86%E7%89%87%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[sharding MySQL5以后提供了Sharding的能力，其目的就是为突破单节点数据服务器I/O能力限制，解决数据库Scale Out水平扩展的问题。通过Sharding可以将数据按照物理位置贴合用户分布，得到更加快速的响应；操作庞然大物总是让人头疼，Sharding将数据分块，更小的数据集操作汇总能够得到更加的体验；分片使得数据分摊在各个数据节点，对其操作实现负载均衡！ 垂直分区 以表为单位，把不同的表分散到不同的数据库或主机上。特点是规则简单，实施方便，适合业务之间耦合度低的系统。 水平分区 以行为单位，将同一个表中的数据按照某种条件拆分到不同的数据库或主机上。特点是相对复杂，适合单表巨大的系统。 静态分片模式 静态分片模式，即分区键是静态分配的，一般使用范围或哈希函数，例如深圳团队放到一个分片，北京团队放到另外一个分片；或者编号为0096开头的员工放到一个分片，而0199开头的员工放到另外一个分片。这种模式虽然实现简单，但明显的缺陷便是存在数据不均匀的情况。 动态分片模式 动态分片模式，即分区函数将从字典中查找分区键，然后定位具体哪个分片存储了数据。这种模式比静态模式更加灵活，但是需要一个集中存储来存放字典，每次查找数据都需要执行2次查询，并且集中存储本身还可能存在单点故障。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>分片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis实战]]></title>
    <url>%2F2017%2F02%2F13%2F%E7%AC%94%E8%AE%B0%2Fredis%E5%AE%9E%E6%88%98%2Fredis%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[redis的持久化redis 是一个支持持久化的内存数据库，也就是说redis需要经常将内存中的数据同步到磁盘来保证持久化。redis 支持两种持久化方式，一种是Snapshotting（快照）也是默认方式，另一种是Append-only file（缩写aof）的方式 snapshotting 方式 快照是默认的持久化方式。这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。可以通过配置设置自动做快照持久化的方式。我们可以配置redis 在n 秒内如果超过m 个key 被修改就自动做快照，下面是默认的快照保存配置 save 900 1 #900 秒内如果超过1 个key 被修改，则发起快照保存 save 300 10 #300 秒内容如超过10 个key 被修改，则发起快照保存 1.redis 调用fork,现在有了子进程和父进程。 2.父进程继续处理client 请求，子进程负责将内存内容写入到临时文件。由于os 的实时复制机制（copy on write)父子进程会共享相同的物理页面，当父进程处理写请求时os 会为父进程要修改的页面创建副本，而不是写共享的页面。所以子进程地址空间内的数据是fork时刻整个数据库的一个快照。 3.当子进程将快照写入临时文件完毕后，用临时文件替换原来的快照文件，然后子进程退出。client 也可以使用save 或者bgsave 命令通知redis 做一次快照持久化。save 操作是在主线程中保存快照的，由于redis 是用一个主线程来处理所有client 的请求，这种方式会阻塞所有client 请求。所以不推荐使用。另一点需要注意的是，每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步变更数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘io 操作，可能会严重影响性能。 aof 方式另外由于快照方式是在一定间隔时间做一次的，所以如果redis 意外down 掉的话，就会丢失最后一次快照后的所有修改。如果应用要求不能丢失任何修改的话，可以采用aof 持久化方式。下面介绍Append-only file:aof 比快照方式有更好的持久化性，是由于在使用aof 持久化方式时,redis 会将每一个收到的写命令都通过write 函数追加到文件中(默认是appendonly.aof)。当redis 重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。当然由于os 会在内核中缓存 write 做的修改，所以可能不是立即写到磁盘上。这样aof 方式的持久化也还是有可能会丢失部分修改。不过我们可以通过配置文件告诉redis 我们想要通过fsync 函数强制os 写入到磁盘的时机。有三种方式如下（默认是：每秒fsync 一次） appendonly yes //启用aof 持久化方 appendfsync always //收到写命令就立即写入磁盘，最慢，但是保证完全的持久化 appendfsync everysec //每秒钟写入磁盘一次，在性能和持久化方面做了很好的折中 appendfsync no //完全依赖os，性能最好,持久化没保证 aof方式产生的问题aof 的方式也同时带来了另一个问题。持久化文件会变的越来越大。例如我们调用incr test命令100 次，文件中必须保存全部的100 条命令，其实有99 条都是多余的。因为要恢复数据库的状态其实文件中保存一条set test 100 就够了。为了压缩aof 的持久化文件。redis 提供了bgrewriteaof 命令。收到此命令redis 将使用与快照类似的方式将内存中的数据以命令的方式保存到临时文件中，最后替换原来的文件。具体过程如下 1、redis 调用fork ，现在有父子两个进程2、子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令3、父进程继续处理client 请求，除了把写命令写入到原来的aof 文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。4、当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。5、现在父进程可以使用临时文件替换老的aof 文件，并重命名，后面收到的写命令也开始往新的aof 文件中追加。 发布及订阅消息发布订阅(pub/sub)是一种消息通信模式，主要的目的是解耦消息发布者和消息订阅者之间的耦合，这点和设计模式中的观察者模式比较相似。pub/sub 不仅仅解决发布者和订阅者直接代码级别耦合也解决两者在物理部署上的耦合。redis 作为一个pub/sub 的server，在订阅者和发布者之间起到了消息路由的功能。订阅者可以通过subscribe 和psubscribe 命令向redisserver 订阅自己感兴趣的消息类型，redis 将消息类型称为通道(channel)。当发布者通过publish 命令向redis server 发送特定类型的消息时。订阅该消息类型的全部client 都会收到此消息。这里消息的传递是多对多的。一个client 可以订阅多个channel,也可以向多个channel发送消息。 Pipeline 批量发送请求利用pipeline 的方式从client 打包多条命令一起发出，不需要等待单条命令的响应返回，而redis 服务端会处理完多条命令后会将多条命令的处理结果打包到一起返回给客户端。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库锁]]></title>
    <url>%2F2017%2F02%2F08%2F%E7%AC%94%E8%AE%B0%2FMySQL%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁的基本概念 锁，在现实生活中是为我们想要隐藏于外界所使用的一种工具。在计算机中，是协调多个进程或线程并发访问某一资源的一种机制。在数据库当中，除了传统的计算资源（CPU、RAM、I/O等等）的争用之外，数据也是一种供许多用户共享访问的资源。如何保证数据并发访问的一致性、有效性，是所有数据库必须解决的一个问题，锁的冲突也是影响数据库并发访问性能的一个重要因素。从这一角度来说，锁对于数据库而言就显得尤为重要。 相对于其他的数据库而言，MySQL的锁机制比较简单，最显著的特点就是不同的存储引擎支持不同的锁机制。根据不同的存储引擎，MySQL中锁的特性可以大致归纳如下： 存储引擎 行锁 表锁 页锁 MyISAM 不支持 支持 不支持 BDB 不支持 支持 支持 InnoDB 支持 支持 不支持 MySQL3种锁的特性： 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 很难笼统的说哪种锁最好，只能根据具体应用的特点来说哪种锁更加合适。仅仅从锁的角度来说的话：表锁更适用于以查询为主，只有少量按索引条件更新数据的应用；行锁更适用于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用。 行锁（Row Lock） 对一行记录加锁，只影响一条记录。常用在DML语句中，如INSERT, UPDATE, DELETE等。InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！1234567891011CREATE TABLE test_index(id int , name VARCHAR(50),age int )engine=innodb ; INSERT INTO test_index values(1,'张一',15); INSERT INTO test_index values(3,'张三',16); INSERT INTO test_index values(4,'张四',17); INSERT INTO test_index values(5,'张五',19); INSERT INTO test_index values(7,'刘琦',19); 直接解释查询：1explain select * from test_index where id = 1; 查询结果：type: all ，rows: 5 很明显是会使用全表锁1234567891011121314151617181920 +----+-------------+------------+------+---------------+------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+------------+------+---------------+------+---------+------+------+-------------+ | 1 | SIMPLE | test_index | ALL | NULL | NULL | NULL | NULL | 5 | Using where | +----+-------------+------------+------+---------------+------+---------+------+------+-------------+``` #### 增加索引，id加唯一索引，age加普通索引``` sqlALTER TABLE test_index ADD UNIQUE uk_id(id),ADD index idx_age(age); mysql&gt; explain select * from test_index where id = 1; 查询结果：锁定一条记录123456789101112 +----+-------------+------------+-------+---------------+-------+---------+-------+------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+------------+-------+---------------+-------+---------+-------+------+-------+ | 1 | SIMPLE | test_index | const | uk_id | uk_id | 5 | const | 1 | NULL | +----+-------------+------------+-------+---------------+-------+---------+-------+------+-------+ type: const ，key:uk_id,rows: 两个事务，TX1加共享行锁, 查询age=17的记录， TX2往数据库里插入一条age=18的记录1234567891011121314151617181920212223242526set autocommit=0;//MySQL默认操作模式就是autocommit自动提交模式。这就表示除非显式地开始一个事务，否则每个查询都被当做一个单独的事务自动执行。我们可以通过设置autocommit的值改变是否是自动提交autocommit模式。值0和OFF都是一样的，当然，1也就表示ON。通过以上设置autocommit=0，则用户将一直处于某个事务中，直到执行一条commit提交或rollback语句才会结束当前事务重新开始一个新的事务。select * from test_index where age=17 lock in share mode;+------+------+------+ | id | name | age | +------+------+------+ | 4 | 张四 | 17 | +------+------+------+ 1 row in set (0.00 sec) TX2:mysql&gt; set autocommit=0; mysql&gt; insert test_index values(8,'test',18); ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 显然被锁住的不止age=17的那一行 执行sql查看加锁的具体信息1select * from information_schema.innodb_locks 表锁 MySQL表级锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。什么意思呢，就是说对MyISAM表进行读操作时，它不会阻塞其他用户对同一表的读请求，但会阻塞 对同一表的写操作；而对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作。 InnoDB锁与MyISAM锁的最大不同在于：一是支持事务（TRANCSACTION），二是采用了行级锁。我们知道事务是由一组SQL语句组成的逻辑处理单元，其有四个属性（简称ACID属性），分别为： 原子性（Atomicity）：事务是一个原子操作单元，其对数据的修改，要么全部执行，要么全都不执行； 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态； 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行； 持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 InnoDB有两种模式的行锁： 共享锁(S)：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。 1( Select * from table_name where ......lock in share mode) 排他锁(X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。 1(select * from table_name where.....for update) 为了允许行锁和表锁共存，实现多粒度锁机制；同时还有两种内部使用的意向锁（都是表锁），分别为意向共享锁和意向排他锁。InnoDB行锁是通过给索引项加锁来实现的，即只有通过索引条件检索数据，InnoDB才使用行级锁，否则将使用表锁！意向共享锁(IS)事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。意向排他锁(IX)事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。 悲观锁正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据） 乐观锁相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 本质上，数据库的乐观锁做法和悲观锁做法主要就是解决下面假设的场景，避免丢失更新问题： 并发事务处理带来的问题相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持更多的用户。但并发事务处理也会带来一些问题，主要包括以下几种情况。更新丢失（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题－－最后的更新覆盖了由其他事务所做的更新。例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改副本的编辑人员覆盖另一个编辑人员所做的更改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题。脏读（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做”脏读”。不可重复读（Non-Repeatable Reads）：一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。幻读（Phantom Reads）：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 MySQL锁机制详细参考链接]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL存储引擎]]></title>
    <url>%2F2017%2F02%2F08%2F%E7%AC%94%E8%AE%B0%2FMySQL%2FMySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[存储引擎 关系数据库表是用于存储和组织信息的数据结构，可以将表理解为由行和列组成的表格，类似于Excel的电子表格的形式。有的表简单，有的表复杂，有的表根本不用来存储任何长期的数据，有的表读取时非常快，但是插入数据时去很差；而我们在实际开发过程中，就可能需要各种各样的表，不同的表，就意味着存储不同类型的数据，数据的处理上也会存在着差异，那么对于MySQL来说，它提供了很多种类型的存储引擎，我们可以根据对数据处理的需求，选择不同的存储引擎，从而最大限度的利用MySQL强大的功能。下面就对MySQL支持的存储引擎进行简单的介绍。 MyISAM MyISAM表是独立于操作系统的，这说明可以轻松地将其从Windows服务器移植到Linux服务器；每当我们建立一个MyISAM引擎的表时，就会在本地磁盘上建立三个文件，文件名就是表名。例如，我建立了一个MyISAM引擎的tb_Demo表，那么就会生成以下三个文件： 1.tb_demo.frm，存储表定义； 2.tb_demo.MYD，存储数据； 3.tb_demo.MYI，存储索引。 MyISAM表无法处理事务，这就意味着有事务处理需求的表，不能使用MyISAM存储引擎。MyISAM存储引擎特别适合在以下几种情况下使用： 1.选择密集型的表。MyISAM存储引擎在筛选大量数据时非常迅速，这是它最突出的优点。 2.插入密集型的表。MyISAM的并发插入特性允许同时选择和插入数据。例如：MyISAM存储引擎很适合管理邮件或Web服务器日志数据。 InnoDB InnoDB是一个健壮的事务型存储引擎(支持事务安全)，这种存储引擎已经被很多互联网公司使用，为用户操作非常大的数据存储提供了一个强大的解决方案。MySQL 5.6.13版，InnoDB就是作为默认的存储引擎。InnoDB还引入了行级锁定和外键约束，在以下场合下，使用InnoDB是最理想的选择： 1.更新密集的表,InnoDB存储引擎特别适合处理多重并发的更新请求。 2.事务，InnoDB存储引擎是支持事务的标准MySQL存储引擎。 3.自动灾难恢复与其它存储引擎不同，InnoDB表能够自动从灾难中恢复。 4.外键约束，MySQL支持外键的存储引擎只有InnoDB。 5.支持自动增加列AUTO_INCREMENT属性。 一般来说，如果需要事务支持，并且有较高的并发读取频率，InnoDB是不错的选择。 MEMORY 使用MySQL Memory存储引擎的出发点是速度。为得到最快的响应时间，采用的逻辑存储介质是系统内存。虽然在内存中存储表数据确实会提供很高的性能，但当mysqld守护进程崩溃时，所有的Memory数据都会丢失。获得速度的同时也带来了一些缺陷。它要求存储在Memory数据表里的数据使用的是长度不变的格式，这意味着不能使用BLOB和TEXT这样的长度可变的数据类型，VARCHAR是一种长度可变的类型，但因为它在MySQL内部当做长度固定不变的CHAR类型，所以可以使用。 一般在以下几种情况下使用Memory存储引擎： 1.目标数据较小，而且被非常频繁地访问。在内存中存放数据，所以会造成内存的使用，可以通过参数max_heap_table_size控制Memory表的大小，设置此参数，就可以限制Memory表的最大大小。 2.如果数据是临时的，而且要求必须立即可用，那么就可以存放在内存表中。 3.存储在Memory表中的数据如果突然丢失，不会对应用服务产生实质的负面影响。 Memory同时支持散列索引和B树索引。B树索引的优于散列索引的是，可以使用部分查询和通配查询，也可以使用&lt;、&gt;和&gt;=等操作符方便数据挖掘。散列索引进行“相等比较”非常快，但是对“范围比较”的速度就慢多了，因此散列索引值适合使用在=和&lt;&gt;的操作符中，不适合在&lt;或&gt;操作符中，也同样不适合用在order by子句中。 使用MEMORY引擎示例：12345678create table users( id smallint unsigned not null auto_increment, username varchar(15) not null, pwd varchar(15) not null, index using hash (username),** index using btree (username)** primary key (id))engine=memory; 在username字段上使用了HASH散列索引 MERGE MERGE存储引擎是一组MyISAM表的组合，这些MyISAM表结构必须完全相同，尽管其使用不如其它引擎突出，但是在某些情况下非常有用。说白了，Merge表就是几个相同MyISAM表的聚合器；Merge表中并没有数据，对Merge类型的表可以进行查询、更新、删除操作，这些操作实际上是对内部的MyISAM表进行操作。Merge存储引擎的使用场景。 对于服务器日志这种信息，一般常用的存储策略是将数据分成很多表，每个名称与特定的时间端相关。例如：可以用12个相同的表来存储服务器日志数据，每个表用对应各个月份的名字来命名。当有必要基于所有12个日志表的数据来生成报表，这意味着需要编写并更新多表查询，以反映这些表中的信息。与其编写这些可能出现错误的查询，不如将这些表合并起来使用一条查询，之后再删除Merge表，而不影响原来的数据，删除Merge表只是删除Merge表的定义，对内部的表没有任何影响。 ARCHIVE Archive是归档的意思，在归档之后很多的高级功能就不再支持了，仅仅支持最基本的插入和查询两种功能。在MySQL 5.5版以前，Archive是不支持索引，但是在MySQL 5.5以后的版本中就开始支持索引了。Archive拥有很好的压缩机制，它使用zlib压缩库，在记录被请求时会实时压缩，所以它经常被用来当做仓库使用。 NDBMySQL 收购的一个集群存储引擎，类似于ORACLE的RAC引擎，但是NDB是share nothing集群架构。NDB的数据都是存储在内存中，所以主键的查找速率很快，并且可以通过增加存储结点，线性增加数据库的性能。 ##查看MySql服务器支持的存储引擎1show engines 存储引擎的选择标准（1）选择标准可以分为：（2）是否需要支持事务；（3）是否需要使用热备；（4）崩溃恢复：能否接受崩溃；（5）是否需要外键支持；]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>存储引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程核心技术]]></title>
    <url>%2F2017%2F02%2F06%2F%E7%AC%94%E8%AE%B0%2Fjava%E5%A4%9A%E7%BA%BF%E7%A8%8B%2Fjava%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Java多线程技能停止线程虽然interrupt有停止、中止的意思，但是不能直接停止当前运行的线程，需要通过调用interrupted或者isInterrupted的状态来判断interrupted:测试当前线程是否处于中断状态，具有清除状态标识将其置为false的功能isInterrupted:测试当前线程是否处于中断状态，不改变状态值1234567891011121314151617181920212223242526272829public class Interrupt extends Thread&#123; public void run()&#123; for (int i=0; i&lt;500000; i++)&#123; super.run(); if (this.isInterrupted())&#123; System.out.println("线程已经停止！退出"); break; &#125; System.out.println("i=:" + (i+1)); &#125; &#125;&#125;--测试public class Interrupted_test &#123; public static void main(String[] args) &#123; try &#123; Interrupt interrupt = new Interrupt(); interrupt.setName("A"); interrupt.start(); Thread.sleep(2000); interrupt.interrupt(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 异常法 通过捕获异常interruptedException，停止线程12345678910111213141516171819public class Interrupt extends Thread&#123; public void run()&#123; try &#123; for (int i=0; i&lt;500000; i++)&#123; super.run(); if (this.isInterrupted())&#123; System.out.println("线程已经停止！退出"); throw new InterruptedException(); &#125; System.out.println("i=:" + (i+1)); &#125; System.out.println("我还要继续执行呢，狠狠！"); &#125;catch (InterruptedException e) &#123; System.out.println("I am interruptedException , i am catched by run! wu wu ...."); e.printStackTrace(); &#125; &#125;&#125; 在线程沉睡中停止在线程sleep时调用interrupted1234567891011121314public class SleepInterrupt extends Thread&#123; public void run() &#123; try&#123; System.out.println("run begin--&gt; oo oo"); Thread.sleep(2000); System.out.println("run end--&gt; ......"); &#125; catch(InterruptedException e) &#123; System.out.println("I am dead in sleeping ......"); e.printStackTrace(); &#125; &#125;&#125; 暴力停止stop用stop的方法停止线程的方式不推荐使用，这是一种不安全的停止方式,暴力停止可能会导致一些清理操作无法执行。 return停止线程run()方法中直接return便退出线程。 暂停、恢复线程suspend(): 暂停线程resume(): 复线程这种方法极易造成公共同步对象的独占，阻止其他线程访问公共同步方法;同时该方法也容易造成数据不同步的问题。123456789101112131415161718192021222324252627public class PrintLock extends Thread &#123; private long i = 0; public void run()&#123; while (true) &#123; // if (this.isInterrupted()) return; i++; //System.out.println("i=:"+i);&lt;!--试试--&gt; &#125; &#125;&#125;--测试public class PrintLock_test &#123; public static void main(String[] args) &#123; try &#123; PrintLock printLock = new PrintLock(); printLock.setName("binary"); printLock.start(); Thread.sleep(1000); printLock.suspend(); System.out.println("main end!"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 当线程获取print()的同步锁未释放时，主线程无法使用println(), println()源码如下：123456public void println(String x) &#123; synchronized (this) &#123; print(x); newLine(); &#125; &#125; yield 线程调用yield()让出cpu，之后再获取cpu继续执行，期间间隔的时间不确定。 线程的优先级线程优先级有10个等级，1-10，设置优先级setPriority()。优先级较高的线程得到的cpu资源较多，也就是说cpu优先执行优先级较高的线程中对象中的任务。 优先级的继承性线程的优先级与启动的线程的优先级一样。 优先级具有规则性优先级具有随机性守护线程Java线程中有两种线程，一种用户线程，另一种为守护线程。守护线程为非守护线程服务，当进程中没有非守护线程的时候，守护线程就会自动销毁，典型的如垃圾回收线程GC。只要当前的JVM虚拟机中存在任何一个非守护线程实例，守护线程就会一直工作。setDaemon()将线程设置为守护线程。 对象及变量的并发访问synchronized 方法非线程安全就是在多个线程对同一个对象的一个实例变量进行并发访问时出现“脏读”的现象，读到的数据是被修改过的，线程安全就是获取的实例变量的值是同步处理的，避免脏读现象。 实例变量的线程安全方法内的变量是线程安全的，然而多个线程并发访问同一个对象的实例变量就是非线程安全的，此时会出现脏读。1234567891011121314151617public class synch &#123; //private int num = 0; 非线程安全 public void addI(String name) &#123; int num = 0; if(name.eq("a"))&#123; num = 100; try &#123; Thread.sleep(1000);&#125; catch(InterruptedException e)&#123; e.printStackTrace(); &#125; else&#123; num = 200; &#125; &#125; &#125;&#125; 这种情况就是在addI()方法加上synchronized锁。 多个对象多个锁synchronized只能锁住同一个对象实例的一个方法，同一对象的多个实例不受约束，通过synchronized锁住的方法只能顺序访问。 脏读1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class MyObject &#123; private String name = "A"; private String pwd = "AA"; synchronized public void setValue(String _name, String _pwd)&#123; this.name = _name; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; this.pwd = _pwd; &#125; /*synchronized*/ public void getValue()&#123; System.out.println(Thread.currentThread().getName()+"name:"+this.name+"&amp;"+"pwd:"+this.pwd); &#125;&#125;/** * Created by song.yang on 2017/3/2：17:00. * &lt;p&gt; * e-mail:song.yang@msxf.com */public class MyThread extends Thread &#123; private MyObject mo; public MyThread(MyObject _mo) &#123; this.mo = _mo; &#125; public void run()&#123; mo.setValue("B", "BB"); &#125;&#125;public class MyTest &#123; public static void main(String[] args) &#123; MyObject mo = new MyObject(); MyThread mt = new MyThread(mo); mt.start(); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; mo.getValue(); &#125;&#125; 线程调用对象的同步方法获得对象锁，其他线程不能获取对象的锁，即其他线程不能调用该对象的所有同步方法，但是其他线程可以调用该对象的非同步方法。 synchronized 锁重入一个线程获取对象锁之后，是可以连续请求以连续获得该对象的锁，即在一个synchronized修饰的方法块内再次调用该对象的其他同步方法是可以的。 synchronized 锁释放出现异常，直接自动释放锁 同步不具有继承性synchronized方法不能继承，在子类方法中添加synchronized修饰才能实现同步。 synchronized同步语句块使用synchronized容易出现长时间等待的现象 锁非this对象非this锁不会与this锁争抢对象锁，这样可以大大提高执行效率，不会发生长时间等待。123456789101112131415161718192021/** * Created by song.yang on 2017/3/7：14:02. * &lt;p&gt; * e-mail:song.yang@msxf.com */public class MyService &#123; public MyList addMyService(MyList ml,String str)&#123; try &#123; synchronized(ml)&#123; if (ml.getSize()&lt;1)&#123; Thread.sleep(2000); ml.addList(str); &#125; &#125; &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return ml; &#125;&#125; ####静态同步synchronized方法与synchronized（class）代码块synchronized加到静态方法上，锁住的是class;synchronized加到非静态方法上，锁住的是对象。而锁住的是class锁可以对类的所有实例对象起作用 数据类型String的常量池特性JVM中具有String常量池缓存的功能，对象不具有1234567891011121314151617181920/** * Created by song.yang on 2017/3/9：13:47. * &lt;p&gt; * e-mail:song.yang@msxf.com */public class Service &#123; public void print(String object)&#123; synchronized(object)&#123; while (true)&#123; System.out.println(Thread.currentThread().getName()); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; Volatile volatile是强制从公共堆栈中获取变量值，而不是从线程私有数据栈中获取变量值 volatile与synchronized的比较关键字volatile是线程同步的轻量级实现，性能比synchronized好，volatile只能修数变量，而synchronized可以修饰方法和代码块，随着JDK版本的提升，synchronized的性能得到提升；多线程访问volatile不会发生阻塞，而多线程访问synchronized会发生阻塞；volatile可以保证数据的可见性，但不能保证数据的原子性，synchronized可以保证数据的原子性，也可以间接保证数据的可见性，因为它将会同步私有内存数据域和公共内存数据域的变量值；volatile可以保证多个线程访问变量的可见性，synchronized保证多个线程访问资源的同步性。volatile只能保证线程从内存中加载数据时是最新的，也就是读数据的时候是最新的，多个线程访问同一个实例变量还是要加锁保证同步。 线程间通信共享实例变量实现通信通知/等待机制wait/notify通知等待机制，二者都要在同步方法中，都需要获得对象锁。wait(): 使调用wait的线程释放共享资源的锁，进入等待队列，直到再次被唤醒notify(): 随机唤醒等待队列中等待同一个资源的线程，被选中的线程退出等待队列，进入可执行状态notifyall(): 唤醒等待队列中所有等待同一资源的线程，全部进入可运行状态，此时优先级最高的线程最先运行，也可能随机执行，具体取决于JVM的实现机制wait()执行之后会自动释放锁，notify()不会自动释放锁，只有在其所在的同步块执行完之后才释放锁 wait(long) 在等待一段时间之内没被唤醒则自动唤醒 join()join()是让所属的线程t正常执行，其他线程进入阻塞队列，在t执行完成之后，阻塞队列中的线程才能继续执行。join(long): 设置等待时间，底层实现是wait(long), 能够自动释放当前锁，之后其他线程可以获取该对象的同步方法sleep(long): 与join(long)不同的是sleep(long)不能自动释放锁 ThreadLocalThreadLocal为线程绑定私有变量 Lock的使用使用ReentrantLock类ReentrantLock与synchronized作用类似，有lock()和nulock(); Timer单例模式与多线程立即加载/饿汉模式立即加载就是在使用类的时候已经创建完毕，常见的方法就是new实例化，而立即加载有着急、急迫的意思，所以称为饿汉模式 延迟加载/懒汉模式延迟加载就是调用get()方法时候才创建实例，常见的情况就是直接在get()方法中实例化，而延迟加载就是在从中文的语境的来看有缓慢和不急迫的意思，故称为懒汉模式。延迟加载根本不能实现安全单例，只能在get()方法加同步synchronized锁才可以,但是该方法效率不高，也可以改成synchronized代码块的方法，但是同样效率低 使用DCL双检查锁机制12345678910111213141516171819202122232425262728293031/** * Created by song.yang on 2017/3/11：14:52. * &lt;p&gt; * e-mail:song.yang@msxf.com */public class MyObject &#123; private volatile static MyObject myObject; private MyObject()&#123; &#125; public static MyObject getInstance()&#123; if (myObject != null)&#123; &#125;else &#123; try &#123; Thread.sleep(1000); synchronized (MyObject.class)&#123; if (myObject == null)&#123; myObject = new MyObject(); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; return myObject; &#125;&#125; 使用静态内置类实现锁机制1234567891011121314151617181920/** * Created by song.yang on 2017/3/11：15:17. * &lt;p&gt; * e-mail:song.yang@msxf.com */public class StaticClass &#123; private static final Logger logger = LoggerFactory.getLogger(StaticClass.class); private static class StaticHandler&#123; private static StaticClass staticClass = new StaticClass(); &#125; private StaticClass()&#123; &#125; public static StaticClass getInstance()&#123; logger.info("静态内置类实现单例模式。。。。"); return StaticHandler.staticClass; &#125;&#125; 序列化和反序列化的单例模式实现静态内置类能够达到单例模式的效果，但是在实现序列化的时候，如果按照默认的的方式则结果还是多例的12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * Created by song.yang on 2017/3/11：15:44. * &lt;p&gt; * e-mail:song.yang@msxf.com */public class MyObject implements Serializable&#123; private static final Logger logger = LoggerFactory.getLogger(MyObject.class); private final static long serialVersionUID = -1L; private static class ObjectClass&#123; private static final MyObject myObject = new MyObject(); &#125; private MyObject()&#123; &#125; public static MyObject getInstance()&#123; return ObjectClass.myObject; &#125;/** 那么这个readResolve()方法是从哪来的，为什么加上之后就能返回同一实例了呢？ 找到ObjectInputStream类的 * Reads and returns "ordinary" (i.e., not a String, Class, * ObjectStreamClass, array, or enum constant) object, or null if object's * class is unresolvable (in which case a ClassNotFoundException will be * associated with object's handle). Sets passHandle to object's assigned * handle.private Object readOrdinaryObject(boolean unshared) throws IOException&#123; if (bin.readByte() != TC_OBJECT) &#123; throw new InternalError(); &#125; ObjectStreamClass desc = readClassDesc(false); desc.checkDeserialize(); Class&lt;?&gt; cl = desc.forClass(); if (cl == String.class || cl == Class.class || cl == ObjectStreamClass.class) &#123; throw new InvalidClassException("invalid class descriptor"); &#125; Object obj; try &#123; obj = desc.isInstantiable() ? desc.newInstance() : null; &#125; catch (Exception ex) &#123; throw (IOException) new InvalidClassException( desc.forClass().getName(), "unable to create instance").initCause(ex); &#125; passHandle = handles.assign(unshared ? unsharedMarker : obj); ClassNotFoundException resolveEx = desc.getResolveException(); if (resolveEx != null) &#123; handles.markException(passHandle, resolveEx); &#125; if (desc.isExternalizable()) &#123; readExternalData((Externalizable) obj, desc); &#125; else &#123; readSerialData(obj, desc); &#125; handles.finish(passHandle); if (obj != null &amp;&amp; handles.lookupException(passHandle) == null &amp;&amp; desc.hasReadResolveMethod()) &#123; Object rep = desc.invokeReadResolve(obj); if (unshared &amp;&amp; rep.getClass().isArray()) &#123; rep = cloneArray(rep); &#125; if (rep != obj) &#123; handles.setObject(passHandle, obj = rep); &#125; &#125; return obj;&#125; */ protected Object readResolve()&#123; System.out.println("调用了readResolve方法！"); return ObjectClass.myObject; &#125;&#125; 使用static代码块实现单例模式static代码块中的代码代码在使用类的时候已经执行了123456789101112131415161718/** * Created by song.yang on 2017/3/11：16:50. * &lt;p&gt; * e-mail:song.yang@msxf.com */public class StaticSingleton &#123; private static StaticSingleton instance = null; private StaticSingleton()&#123; &#125; static &#123; instance = new StaticSingleton(); &#125; public static StaticSingleton getInstance()&#123; return instance; &#125;&#125; 使用enum枚举数据类型实现单例模式在使用枚举数据类型时，构造方法会被自动调用，可以根据这个特性实现单例模式 拾遗增补线程状态调用线程的getState(), 线程状态new,runnable,running,terminated,timed_waiting,blocked,waiting, 线程组线程对象关联线程组：1级关联父对象与子对象 线程 对象关联线程组：多级关联父对象与子对象以及孙子对象 线程具有有序性SimpleDateFormate非线程安全SimpleDateFormate类是非线程安全的，]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>thread</tag>
      </tags>
  </entry>
</search>